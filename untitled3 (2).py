# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PGL4cztw3pA3Qiq5yzeXblix7yV92obR

submission taruna rachmad riyadi
Kota Jakarta Utara, DKI Jakarta
"""

# !wget --no-check-certificate \
#   https://dicodingacademy.blob.core.windows.net/picodiploma/ml_pemula_academy/rockpaperscissors.zip

!wget --no-check-certificate \
  https://github.com/dicodingacademy/assets/releases/download/release/rockpaperscissors.zip

# import shutil

# base_dir = '/tmp/rockpaperscissors'

# shutil.rmtree(os.path.join(base_dir, 'rps-cv-images'))

# os.remove(os.path.join(base_dir, 'README_rpc-cv-images.txt'))

# !tree -d '/tmp/rockpaperscissors/rps-cv-images'
# os.remove('/tmp/rockpaperscissors/README_rpc-cv-images.txt')
# !rm /tmp/rockpaperscissors/README_rpc-cv-images.txt

# !rm -rf /tmp/rockpaperscissors/rps-cv-images/train
# !rm -rf /tmp/rockpaperscissors/rps-cv-images/val
# !ls '/tmp/rockpaperscissors/data/train/'

!tree -d '/tmp/rockpaperscissors/rps-cv-images'
# os.remove('/tmp/rockpaperscissors/README_rpc-cv-images.txt')
# !rm /tmp/rockpaperscissors/README_rpc-cv-images.txt
!rm -rf /tmp/rockpaperscissors/rps-cv-images/train
!rm -rf /tmp/rockpaperscissors/rps-cv-images/val
!rm -rf /tmp/rockpaperscissors/

!pip install split-folders #https://pypi.org/project/split-folders/
import splitfolders
import zipfile,os

local_zip = 'rockpaperscissors.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/tmp')
zip_ref.close()
 
base_dir = '/tmp/rockpaperscissors'
import shutil
shutil.rmtree('/tmp/rockpaperscissors/rps-cv-images', ignore_errors=True)
 
import splitfolders
splitfolders.ratio(base_dir, output=base_dir, ratio=(0.8,0.2))
 
train_dir = os.path.join(base_dir, 'train')
validation_dir = os.path.join(base_dir, 'val')
 
os.listdir(train_dir)

"""preprocessing training set"""

import tensorflow as tf
from keras.preprocessing.image import ImageDataGenerator
# from tensorflow.keras.models import Sequential
train_datagen = ImageDataGenerator(
  rescale=1./255, 
  shear_range=0.2, 
  zoom_range=0.2, 
  horizontal_flip=True) 
train_generator = train_datagen.flow_from_directory(
  train_dir, 
  target_size=(64, 64),
  batch_size=32,   class_mode='categorical',
)

"""preprocessing test set"""

validation_datagen = ImageDataGenerator(rescale=1./255, validation_split= 0.5)
valid_generator = validation_datagen.flow_from_directory(
            validation_dir, 
            target_size=(64,64), 
            batch_size=32, 
            class_mode='categorical',
)

# train_generator.class_indices
# valid_generator.class_indices

"""initialising the cnn"""

cnn = tf.keras.models.Sequential()

"""convolution """

cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))

"""pooling"""

cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))

"""second convolutional layer"""

cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))
cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))

"""flattening"""

cnn.add(tf.keras.layers.Flatten())

"""full connection"""

cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))

"""output layer"""

cnn.add(tf.keras.layers.Dense(units=3, activation='softmax'))

class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy')>0.97 and logs.get('val_accuracy')>0.97):
      print("\nAccuracy above 92%, finish training!")
      self.model.stop_training = True

callbacks = myCallback()

"""training the cnn
compiling the cnn
"""

cnn.compile(optimizer = 'adam',
              loss = 'categorical_crossentropy',
              metrics = ['accuracy'])

# Training the CNN on the Training set and evaluating it on the Test set
history = cnn.fit(x = train_generator, validation_data = valid_generator, epochs = 20, callbacks=[callbacks])

import matplotlib.pyplot as plt
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()

"""single prediction"""

# from google.colab import files
# from keras.preprocessing import image
# import numpy as np
# # import matplotlib.pyplot as plt
# %matplotlib inline
 
# uploaded = files.upload()
 
# for fn in uploaded.keys():
 
  
#   path = fn
#   img = image.load_img(path, target_size=(64,64))
#   imgplot = plt.imshow(img)
#   x = image.img_to_array(img)
#   x = np.expand_dims(x, axis=0)
 
#   images = np.vstack([x])
#   classes = cnn.predict(images, batch_size=32)
  
#   print(fn)
#   if classes[0,0] == 1.0:
#     print('Paper')
#   elif classes[0,1] == 1.0:
#     print('Rock')
#   else:
#     print('Scissors')

converter = tf.lite.TFLiteConverter.from_keras_model(cnn)
tflite_model = converter.convert()

with tf.io.gfile.GFile('model.tflite', 'wb') as f:
  f.write(tflite_model)